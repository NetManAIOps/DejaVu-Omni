{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_ts=1709442000\n",
      "metrics_before: 4437, metrics_after: 4737, metrics: 4258\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.realpath(\"..\"))\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "DATASET = 'E'\n",
    "WORK_DIR = Path(f\"../data/{DATASET}\")\n",
    "drift_ranges = [1709449200, 1709488800, 1709571600, 1711548600, 1711574700, 1711599900, 1711611600, 1711634400, 1711682400, 1712052000, 1712080800, 1712116800, 1712145600, 1712167200, 1712188800, 1712491200, 1712530800, 1712595600, 1712682000, 1712854800, 1712867400]\n",
    "fault_df = pd.read_csv(WORK_DIR / \"faults.csv\")\n",
    "with open(WORK_DIR / \"drift.txt\", 'r') as f:\n",
    "    drift_ts = int(f.read())\n",
    "print(f\"{drift_ts=}\")\n",
    "metric_df = pd.read_pickle(WORK_DIR / \"metrics.norm.pkl\")\n",
    "failure_timestamps = []\n",
    "for _, failure in fault_df.iterrows():\n",
    "    timestamp = failure['timestamp']\n",
    "    failure_timestamps.extend([timestamp + i*60 for i in range(0, 20)])\n",
    "\n",
    "metric_index_dict = metric_df.groupby(['name']).groups\n",
    "metric_index_after_dict = metric_df[metric_df.timestamp>=drift_ts & ~(metric_df.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df[(metric_df.timestamp<drift_ts) & ~(metric_df.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "metrics_after = set(metric_index_after_dict.keys())\n",
    "metrics = list(metrics_before & metrics_after)\n",
    "metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DejaVu-Omni (Ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_ours = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metric_df_ours.groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df_ours[(metric_df_ours.timestamp<drift_ts) & ~(metric_df_ours.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_dict = metric_df_ours[(metric_df_ours.timestamp>=drift_start) & (metric_df_ours.timestamp<drift_end) & ~(metric_df_ours.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metric_index_after_all_dict = metric_df_ours[(metric_df_ours.timestamp>=drift_start) & (metric_df_ours.timestamp<drift_end)].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metric_df_ours.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()[-120:]\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:90]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        before_median = before_metrics_value.median()\n",
    "        before_IQR = before_metrics_value.quantile(0.75) - before_metrics_value.quantile(0.25)\n",
    "        after_metrics_value = after_metrics.value\n",
    "        after_median = after_metrics_value.median()\n",
    "        after_IQR = after_metrics_value.quantile(0.75) - after_metrics_value.quantile(0.25)\n",
    "        drift_num += 1\n",
    "        drift_metrics.append(metric)\n",
    "        scale = before_IQR / after_IQR if after_IQR != 0 else 1\n",
    "        bias = before_median - after_median * scale\n",
    "\n",
    "        metric_index_after_all = metric_index_after_all_dict[metric]\n",
    "        metrics_data_after_all = metrics_data.loc[metric_index_after_all]\n",
    "        after_metrics_value_all = metrics_data_after_all['value'].values * scale + bias\n",
    "        metric_df_ours.loc[metric_index_after_all, 'value'] = after_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [ours] in range ({drift_start}, {drift_end})\")\n",
    "metric_df_ours.to_pickle(WORK_DIR / f'metrics.norm.drift.ours.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DejaVu-ICPP‘19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_start=1709449200 drift_end=1709488800\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [01:13<00:00, 57.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2307 metrics using method [icpp] in range (1709449200, 1709488800)\n",
      "drift_start=1709488800 drift_end=1709571600\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [01:15<00:00, 56.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2498 metrics using method [icpp] in range (1709488800, 1709571600)\n",
      "drift_start=1709571600 drift_end=1711548600\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [01:19<00:00, 53.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2365 metrics using method [icpp] in range (1709571600, 1711548600)\n",
      "drift_start=1711548600 drift_end=1711574700\n",
      "metrics_before: 4437, metrics_after: 4259, metrics: 4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4230/4230 [01:01<00:00, 69.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2441 metrics using method [icpp] in range (1711548600, 1711574700)\n",
      "drift_start=1711574700 drift_end=1711599900\n",
      "metrics_before: 4437, metrics_after: 4259, metrics: 4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4230/4230 [00:58<00:00, 72.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2395 metrics using method [icpp] in range (1711574700, 1711599900)\n",
      "drift_start=1711599900 drift_end=1711611600\n",
      "metrics_before: 4437, metrics_after: 0, metrics: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 0 metrics using method [icpp] in range (1711599900, 1711611600)\n",
      "drift_start=1711611600 drift_end=1711634400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [00:57<00:00, 73.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2366 metrics using method [icpp] in range (1711611600, 1711634400)\n",
      "drift_start=1711634400 drift_end=1711682400\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [01:04<00:00, 66.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2486 metrics using method [icpp] in range (1711634400, 1711682400)\n",
      "drift_start=1711682400 drift_end=1712052000\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [01:02<00:00, 67.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2374 metrics using method [icpp] in range (1711682400, 1712052000)\n",
      "drift_start=1712052000 drift_end=1712080800\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [00:58<00:00, 72.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2402 metrics using method [icpp] in range (1712052000, 1712080800)\n",
      "drift_start=1712080800 drift_end=1712116800\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [01:02<00:00, 67.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2435 metrics using method [icpp] in range (1712080800, 1712116800)\n",
      "drift_start=1712116800 drift_end=1712145600\n",
      "metrics_before: 4437, metrics_after: 4263, metrics: 4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4234/4234 [00:56<00:00, 74.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2397 metrics using method [icpp] in range (1712116800, 1712145600)\n",
      "drift_start=1712145600 drift_end=1712167200\n",
      "metrics_before: 4437, metrics_after: 0, metrics: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 0 metrics using method [icpp] in range (1712145600, 1712167200)\n",
      "drift_start=1712167200 drift_end=1712188800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_before: 4437, metrics_after: 4300, metrics: 4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4246/4246 [00:59<00:00, 71.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2578 metrics using method [icpp] in range (1712167200, 1712188800)\n",
      "drift_start=1712188800 drift_end=1712491200\n",
      "metrics_before: 4437, metrics_after: 4098, metrics: 4069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4069/4069 [00:54<00:00, 74.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2030 metrics using method [icpp] in range (1712188800, 1712491200)\n",
      "drift_start=1712491200 drift_end=1712530800\n",
      "metrics_before: 4437, metrics_after: 4095, metrics: 4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4066/4066 [00:56<00:00, 71.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2063 metrics using method [icpp] in range (1712491200, 1712530800)\n",
      "drift_start=1712530800 drift_end=1712595600\n",
      "metrics_before: 4437, metrics_after: 4095, metrics: 4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4066/4066 [00:57<00:00, 70.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2180 metrics using method [icpp] in range (1712530800, 1712595600)\n",
      "drift_start=1712595600 drift_end=1712682000\n",
      "metrics_before: 4437, metrics_after: 4095, metrics: 4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4066/4066 [00:56<00:00, 72.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2115 metrics using method [icpp] in range (1712595600, 1712682000)\n",
      "drift_start=1712682000 drift_end=1712854800\n",
      "metrics_before: 4437, metrics_after: 4120, metrics: 4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4066/4066 [00:57<00:00, 70.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 2051 metrics using method [icpp] in range (1712682000, 1712854800)\n",
      "drift_start=1712854800 drift_end=1712867400\n",
      "metrics_before: 4437, metrics_after: 4095, metrics: 4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drift metrics: 100%|██████████| 4066/4066 [00:55<00:00, 73.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully drift 1975 metrics using method [icpp] in range (1712854800, 1712867400)\n"
     ]
    }
   ],
   "source": [
    "metric_df_icpp = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metric_df_icpp.groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df_icpp[(metric_df_icpp.timestamp<drift_ts) & ~(metric_df_icpp.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_dict = metric_df_icpp[(metric_df_icpp.timestamp>=drift_start) & (metric_df_icpp.timestamp<drift_end) & ~(metric_df_icpp.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metric_index_after_all_dict = metric_df_icpp[(metric_df_icpp.timestamp>=drift_start) & (metric_df_icpp.timestamp<drift_end)].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metric_df_icpp.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()[-120:]\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:90]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        before_mean = before_metrics_value.mean()\n",
    "        before_std = before_metrics_value.std()\n",
    "        after_metrics_value = after_metrics.value\n",
    "        after_mean = after_metrics_value.mean()\n",
    "        after_std = after_metrics_value.std()\n",
    "        drift_num += 1\n",
    "        drift_metrics.append(metric)\n",
    "        scale = before_std / after_std if after_std != 0 else 1\n",
    "        bias = before_mean - after_mean * scale\n",
    "\n",
    "        metric_index_after_all = metric_index_after_all_dict[metric]\n",
    "        metrics_data_after_all = metrics_data.loc[metric_index_after_all]\n",
    "        after_metrics_value_all = metrics_data_after_all['value'].values * scale + bias\n",
    "        metric_df_icpp.loc[metric_index_after_all, 'value'] = after_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [icpp] in range ({drift_start}, {drift_end})\")\n",
    "metric_df_icpp.to_pickle(WORK_DIR / f'metrics.norm.drift.icpp_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_icpp = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metrics_df_icpp.groupby(['name']).groups\n",
    "metric_index_before_dict = metrics_df_icpp[(metrics_df_icpp.timestamp<drift_ts) & ~(metrics_df_icpp.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metric_index_before_all_dict = metrics_df_icpp[(metrics_df_icpp.timestamp<drift_ts)].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_dict = metrics_df_icpp[(metrics_df_icpp.timestamp>=drift_start) & (metrics_df_icpp.timestamp<drift_end) & ~(metrics_df_icpp.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metrics_df_icpp.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()[-120:]\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:30]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        before_mean = before_metrics_value.mean()\n",
    "        before_std = before_metrics_value.std()\n",
    "        after_metrics_value = after_metrics.value\n",
    "        after_mean = after_metrics_value.mean()\n",
    "        after_std = after_metrics_value.std()\n",
    "        if after_std == 0:\n",
    "            continue\n",
    "        drift_num += 1\n",
    "        drift_metrics.append(metric)\n",
    "        scale = after_std / before_std if before_std != 0 else 1\n",
    "        bias = after_mean - before_mean * scale\n",
    "\n",
    "        metric_index_before_all = metric_index_before_all_dict[metric]\n",
    "        metrics_data_before_all = metrics_data.loc[metric_index_before_all]\n",
    "        before_metrics_value_all = metrics_data_before_all['value'].values * scale + bias\n",
    "        metrics_df_icpp.loc[metric_index_before_all, 'value'] = before_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [icpp] in range ({drift_start}, {drift_end})\")\n",
    "metrics_df_icpp.to_pickle(WORK_DIR / f'metrics.norm.drift.icpp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DejaVu-StepWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "metric_df_stepwise = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metric_df_stepwise.groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df_stepwise[(metric_df_stepwise.timestamp<drift_ts) & ~(metric_df_stepwise.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_all_dict = metric_df_stepwise[(metric_df_stepwise.timestamp>=drift_start) & (metric_df_stepwise.timestamp<drift_end)].groupby(['name']).groups\n",
    "    metric_index_after_dict = metric_df_stepwise[(metric_df_stepwise.timestamp>=drift_start) & (metric_df_stepwise.timestamp<drift_end) & ~(metric_df_stepwise.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metric_df_stepwise.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:30]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        \n",
    "        ts_medians = np.zeros(24*60//17, dtype=np.float32)\n",
    "        mod = 5040      # 24*60*60//17\n",
    "        for i in range(24*60//17):\n",
    "            tmp = before_metrics.loc[before_metrics.timestamp % mod == i*60].sort_values(by=['timestamp']).drop_duplicates()[-10:]['value']\n",
    "            ts_medians[i] = tmp.median(skipna=True)\n",
    "        ts_medians[np.isnan(ts_medians)] = 0\n",
    "        target_series = []\n",
    "        for i in range(after_metrics.shape[0]):\n",
    "            tmp = after_metrics.iloc[i]\n",
    "            timestamp = tmp['timestamp']\n",
    "            target_series.append(ts_medians[(timestamp%mod)//60])\n",
    "        target_series = np.array(target_series)\n",
    "        rlr = RANSACRegressor()\n",
    "        rlr.fit(np.array(after_metrics.value).reshape((-1, 1)), target_series)\n",
    "\n",
    "        metric_index_after_all = metric_index_after_all_dict[metric]\n",
    "        metrics_data_after_all = metrics_data.loc[metric_index_after_all]\n",
    "        after_metrics_value_all = rlr.predict(metrics_data_after_all['value'].values.reshape((-1, 1)))\n",
    "        metric_df_stepwise.loc[metric_index_after_all, 'value'] = after_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [stepwise] in range ({drift_start}, {drift_end})\")\n",
    "metric_df_stepwise.to_pickle(WORK_DIR / f'metrics.norm.drift.stepwise.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
