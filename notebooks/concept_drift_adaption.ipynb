{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_ts=1709442000\n",
      "metrics_before: 4437, metrics_after: 4737, metrics: 4258\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.realpath(\"..\"))\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "DATASET = 'E'\n",
    "WORK_DIR = Path(f\"/SSF/data/{DATASET}\")\n",
    "drift_ranges = [1709449200, 1709488800, 1709571600, 1711548600, 1711574700, 1711599900, 1711611600, 1711634400, 1711682400, 1712052000, 1712080800, 1712116800, 1712145600, 1712167200, 1712188800, 1712491200, 1712530800, 1712595600, 1712682000, 1712854800, 1712867400]\n",
    "fault_df = pd.read_csv(WORK_DIR / \"faults.csv\")\n",
    "with open(WORK_DIR / \"drift.txt\", 'r') as f:\n",
    "    drift_ts = int(f.read())\n",
    "print(f\"{drift_ts=}\")\n",
    "metric_df = pd.read_pickle(WORK_DIR / \"metrics.norm.pkl\")\n",
    "failure_timestamps = []\n",
    "for _, failure in fault_df.iterrows():\n",
    "    timestamp = failure['timestamp']\n",
    "    failure_timestamps.extend([timestamp + i*60 for i in range(0, 20)])\n",
    "\n",
    "metric_index_dict = metric_df.groupby(['name']).groups\n",
    "metric_index_after_dict = metric_df[metric_df.timestamp>=drift_ts & ~(metric_df.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df[(metric_df.timestamp<drift_ts) & ~(metric_df.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "metrics_after = set(metric_index_after_dict.keys())\n",
    "metrics = list(metrics_before & metrics_after)\n",
    "metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DejaVu-Omni (Ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_ours = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metric_df_ours.groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df_ours[(metric_df_ours.timestamp<drift_ts) & ~(metric_df_ours.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_dict = metric_df_ours[(metric_df_ours.timestamp>=drift_start) & (metric_df_ours.timestamp<drift_end) & ~(metric_df_ours.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metric_index_after_all_dict = metric_df_ours[(metric_df_ours.timestamp>=drift_start) & (metric_df_ours.timestamp<drift_end)].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metric_df_ours.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()[-120:]\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:90]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        before_median = before_metrics_value.median()\n",
    "        before_IQR = before_metrics_value.quantile(0.75) - before_metrics_value.quantile(0.25)\n",
    "        after_metrics_value = after_metrics.value\n",
    "        after_median = after_metrics_value.median()\n",
    "        after_IQR = after_metrics_value.quantile(0.75) - after_metrics_value.quantile(0.25)\n",
    "        drift_num += 1\n",
    "        drift_metrics.append(metric)\n",
    "        scale = before_IQR / after_IQR if after_IQR != 0 else 1\n",
    "        bias = before_median - after_median * scale\n",
    "\n",
    "        metric_index_after_all = metric_index_after_all_dict[metric]\n",
    "        metrics_data_after_all = metrics_data.loc[metric_index_after_all]\n",
    "        after_metrics_value_all = metrics_data_after_all['value'].values * scale + bias\n",
    "        metric_df_ours.loc[metric_index_after_all, 'value'] = after_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [ours] in range ({drift_start}, {drift_end})\")\n",
    "metric_df_ours.to_pickle(WORK_DIR / f'metrics.norm.drift.ours.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DejaVu-ICPPâ€˜19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_icpp = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metrics_df_icpp.groupby(['name']).groups\n",
    "metric_index_before_dict = metrics_df_icpp[(metrics_df_icpp.timestamp<drift_ts) & ~(metrics_df_icpp.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metric_index_before_all_dict = metrics_df_icpp[(metrics_df_icpp.timestamp<drift_ts)].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_dict = metrics_df_icpp[(metrics_df_icpp.timestamp>=drift_start) & (metrics_df_icpp.timestamp<drift_end) & ~(metrics_df_icpp.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metrics_df_icpp.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()[-120:]\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:30]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        before_mean = before_metrics_value.mean()\n",
    "        before_std = before_metrics_value.std()\n",
    "        after_metrics_value = after_metrics.value\n",
    "        after_mean = after_metrics_value.mean()\n",
    "        after_std = after_metrics_value.std()\n",
    "        if after_std == 0:\n",
    "            continue\n",
    "        drift_num += 1\n",
    "        drift_metrics.append(metric)\n",
    "        scale = after_std / before_std if before_std != 0 else 1\n",
    "        bias = after_mean - before_mean * scale\n",
    "\n",
    "        metric_index_before_all = metric_index_before_all_dict[metric]\n",
    "        metrics_data_before_all = metrics_data.loc[metric_index_before_all]\n",
    "        before_metrics_value_all = metrics_data_before_all['value'].values * scale + bias\n",
    "        metrics_df_icpp.loc[metric_index_before_all, 'value'] = before_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [icpp] in range ({drift_start}, {drift_end})\")\n",
    "metrics_df_icpp.to_pickle(WORK_DIR / f'metrics.norm.drift.icpp.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DejaVu-StepWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "metric_df_stepwise = copy.deepcopy(metric_df)\n",
    "metric_index_dict = metric_df_stepwise.groupby(['name']).groups\n",
    "metric_index_before_dict = metric_df_stepwise[(metric_df_stepwise.timestamp<drift_ts) & ~(metric_df_stepwise.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "metrics_before = set(metric_index_before_dict.keys())\n",
    "for i in range(len(drift_ranges)-1):\n",
    "    drift_num = 0\n",
    "    drift_metrics = []\n",
    "    drift_start, drift_end = drift_ranges[i], drift_ranges[i+1]\n",
    "    print(f\"{drift_start=} {drift_end=}\")\n",
    "    metric_index_after_all_dict = metric_df_stepwise[(metric_df_stepwise.timestamp>=drift_start) & (metric_df_stepwise.timestamp<drift_end)].groupby(['name']).groups\n",
    "    metric_index_after_dict = metric_df_stepwise[(metric_df_stepwise.timestamp>=drift_start) & (metric_df_stepwise.timestamp<drift_end) & ~(metric_df_stepwise.timestamp.isin(failure_timestamps))].groupby(['name']).groups\n",
    "    metrics_after = set(metric_index_after_dict.keys())\n",
    "    metrics = list(metrics_before & metrics_after)\n",
    "    metrics = [metric for metric in metrics if 'loadgenerator' not in metric]\n",
    "    print(f\"metrics_before: {len(metrics_before)}, metrics_after: {len(metrics_after)}, metrics: {len(metrics)}\")\n",
    "    \n",
    "    for metric in tqdm(metrics, desc=\"drift metrics: \"):\n",
    "        if 'fake' in metric:\n",
    "            continue\n",
    "        metric_index = metric_index_dict[metric]\n",
    "        metric_index_after = metric_index_after_dict[metric]\n",
    "        metric_index_before = metric_index_before_dict[metric]\n",
    "        metrics_data = metric_df_stepwise.loc[metric_index]\n",
    "        before_metrics = metrics_data.loc[metric_index_before].sort_values(by=['timestamp']).drop_duplicates()\n",
    "        metrics_data_after = metrics_data.loc[metric_index_after]\n",
    "        after_metrics = metrics_data_after.sort_values(by=['timestamp']).drop_duplicates()[:30]\n",
    "        if before_metrics.empty or after_metrics.empty or len(after_metrics) < 10 or len(after_metrics.value.unique()) == 1:\n",
    "            continue\n",
    "        before_metrics_value = before_metrics.value\n",
    "        \n",
    "        ts_medians = np.zeros(24*60//17, dtype=np.float32)\n",
    "        mod = 5040      # 24*60*60//17\n",
    "        for i in range(24*60//17):\n",
    "            tmp = before_metrics.loc[before_metrics.timestamp % mod == i*60].sort_values(by=['timestamp']).drop_duplicates()[-10:]['value']\n",
    "            ts_medians[i] = tmp.median(skipna=True)\n",
    "        ts_medians[np.isnan(ts_medians)] = 0\n",
    "        target_series = []\n",
    "        for i in range(after_metrics.shape[0]):\n",
    "            tmp = after_metrics.iloc[i]\n",
    "            timestamp = tmp['timestamp']\n",
    "            target_series.append(ts_medians[(timestamp%mod)//60])\n",
    "        target_series = np.array(target_series)\n",
    "        rlr = RANSACRegressor()\n",
    "        rlr.fit(np.array(after_metrics.value).reshape((-1, 1)), target_series)\n",
    "\n",
    "        metric_index_after_all = metric_index_after_all_dict[metric]\n",
    "        metrics_data_after_all = metrics_data.loc[metric_index_after_all]\n",
    "        after_metrics_value_all = rlr.predict(metrics_data_after_all['value'].values.reshape((-1, 1)))\n",
    "        metric_df_stepwise.loc[metric_index_after_all, 'value'] = after_metrics_value_all\n",
    "    print(f\"successfully drift {drift_num} metrics using method [stepwise] in range ({drift_start}, {drift_end})\")\n",
    "metric_df_stepwise.to_pickle(WORK_DIR / f'metrics.norm.drift.stepwise.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
